#!/usr/bin/env python3
"""
æ—¥æœ¬èªãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰æ–‡å­—åˆ—ã®æŠ½å‡ºãƒ»åˆ†é¡ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
Phase 2: å…¨Dartãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰æ—¥æœ¬èªæ–‡å­—åˆ—ã‚’æ¤œå‡ºã—ã€æ—¢å­˜ARBã‚­ãƒ¼ã¨ãƒãƒƒãƒãƒ³ã‚°
"""

import json
import re
import hashlib
from pathlib import Path
from typing import Dict, List, Tuple, Set

class JapaneseStringExtractor:
    def __init__(self):
        self.arb_dir = Path("lib/l10n")
        self.lib_dir = Path("lib")
        self.existing_arb_keys = {}
        self.load_existing_arb()
        
    def load_existing_arb(self):
        """æ—¢å­˜ã®ARBãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆæ—¥æœ¬èªï¼‰ã‚’èª­ã¿è¾¼ã¿"""
        ja_arb_file = self.arb_dir / "app_ja.arb"
        with open(ja_arb_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
            self.existing_arb_keys = {k: v for k, v in data.items() if not k.startswith('@')}
        print(f"âœ… æ—¢å­˜ARBã‚­ãƒ¼æ•°: {len(self.existing_arb_keys)}")
    
    def is_debug_or_log_string(self, text: str) -> bool:
        """ãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°ã‚„ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‹ã©ã†ã‹åˆ¤å®š"""
        debug_markers = ['âŒ', 'âœ…', 'ğŸ“Š', 'ğŸ“…', 'ğŸ”„', 'âš ï¸', 'ğŸ”', 'ğŸ’ª', 
                        'ã‚¨ãƒ©ãƒ¼:', 'Error', 'DEBUG', 'LOG', 'INFO',
                        'é–‹å§‹', 'å®Œäº†', 'å¤±æ•—', 'æˆåŠŸ']
        return any(marker in text for marker in debug_markers)
    
    def extract_japanese_strings_from_file(self, dart_file: Path) -> List[Tuple[int, str]]:
        """Dartãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰æ—¥æœ¬èªæ–‡å­—åˆ—ã‚’æŠ½å‡º"""
        results = []
        try:
            content = dart_file.read_text(encoding='utf-8')
            lines = content.split('\n')
            
            # æ—¥æœ¬èªæ–‡å­—åˆ—ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆã‚·ãƒ³ã‚°ãƒ«ã‚¯ã‚©ãƒ¼ãƒˆã¾ãŸã¯ãƒ€ãƒ–ãƒ«ã‚¯ã‚©ãƒ¼ãƒˆï¼‰
            pattern = re.compile(r'[\'"]([^\'"]*[\u3040-\u309F\u30A0-\u30FF\u4E00-\u9FAF]+[^\'"]*)[\'"]')
            
            for line_num, line in enumerate(lines, 1):
                # ã‚³ãƒ¡ãƒ³ãƒˆè¡Œã‚’ã‚¹ã‚­ãƒƒãƒ—
                if line.strip().startswith('//'):
                    continue
                
                matches = pattern.findall(line)
                for match in matches:
                    # çŸ­ã™ãã‚‹æ–‡å­—åˆ—ã‚„ãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°ã‚’ã‚¹ã‚­ãƒƒãƒ—
                    if len(match) <= 1 or self.is_debug_or_log_string(match):
                        continue
                    
                    # ã‚³ãƒ¼ãƒ‰æ–­ç‰‡ã‚’é™¤å¤–ï¼ˆå¤‰æ•°å®£è¨€ãªã©ï¼‰
                    if any(x in match for x in ['_', '=', ';', '{', '}', '(', ')', '[', ']']):
                        # ãŸã ã—ã€UIãƒ†ã‚­ã‚¹ãƒˆã«å«ã¾ã‚Œã‚‹æ‹¬å¼§ãªã©ã¯è¨±å¯
                        if not any(ui_word in match for ui_word in ['ã‚’', 'ãŒ', 'ã«', 'ã®', 'ã¯', 'ã§ã™', 'ã¾ã™']):
                            continue
                    
                    results.append((line_num, match))
        except Exception as e:
            print(f"âš ï¸  ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {dart_file}: {e}")
        
        return results
    
    def find_matching_arb_key(self, japanese_text: str) -> Tuple[str, str]:
        """
        æ—¥æœ¬èªãƒ†ã‚­ã‚¹ãƒˆã«ä¸€è‡´ã™ã‚‹æ—¢å­˜ã®ARBã‚­ãƒ¼ã‚’æ¤œç´¢
        
        Returns:
            (key_name, match_type) - ('existing_key', 'exact') or (None, None)
        """
        # å®Œå…¨ä¸€è‡´
        for key, value in self.existing_arb_keys.items():
            if value == japanese_text:
                return (key, 'exact')
        
        # éƒ¨åˆ†ä¸€è‡´ï¼ˆçŸ­ã„æ–‡å­—åˆ—ã®ã¿ï¼‰
        if len(japanese_text) <= 10:
            for key, value in self.existing_arb_keys.items():
                if japanese_text in value or value in japanese_text:
                    return (key, 'partial')
        
        return (None, None)
    
    def extract_all_japanese_strings(self) -> Dict:
        """å…¨Dartãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰æ—¥æœ¬èªæ–‡å­—åˆ—ã‚’æŠ½å‡ºã—åˆ†é¡"""
        all_strings = {}
        matched_count = 0
        new_needed_count = 0
        
        dart_files = list(self.lib_dir.rglob("*.dart"))
        print(f"\nğŸ” {len(dart_files)}å€‹ã®Dartãƒ•ã‚¡ã‚¤ãƒ«ã‚’è§£æä¸­...")
        
        for dart_file in dart_files:
            extracted = self.extract_japanese_strings_from_file(dart_file)
            
            for line_num, jp_text in extracted:
                # æ—¢ã«å‡¦ç†æ¸ˆã¿ã®æ–‡å­—åˆ—ã¯ã‚¹ã‚­ãƒƒãƒ—
                if jp_text in all_strings:
                    all_strings[jp_text]['locations'].append(f"{dart_file}:{line_num}")
                    continue
                
                # æ—¢å­˜ARBã‚­ãƒ¼ã¨ãƒãƒƒãƒãƒ³ã‚°
                existing_key, match_type = self.find_matching_arb_key(jp_text)
                
                if existing_key:
                    matched_count += 1
                    all_strings[jp_text] = {
                        'text': jp_text,
                        'existing_key': existing_key,
                        'match_type': match_type,
                        'needs_new_key': False,
                        'locations': [f"{dart_file}:{line_num}"]
                    }
                else:
                    new_needed_count += 1
                    # æ–°è¦ã‚­ãƒ¼åã‚’ç”Ÿæˆ
                    text_hash = hashlib.md5(jp_text.encode('utf-8')).hexdigest()[:8]
                    new_key = f"autoGen_{text_hash}"
                    
                    all_strings[jp_text] = {
                        'text': jp_text,
                        'existing_key': None,
                        'new_key': new_key,
                        'needs_new_key': True,
                        'locations': [f"{dart_file}:{line_num}"]
                    }
        
        print(f"\nğŸ“Š æ¤œå‡ºçµæœ:")
        print(f"   ç·æ—¥æœ¬èªæ–‡å­—åˆ—æ•°: {len(all_strings)}")
        print(f"   âœ… æ—¢å­˜ã‚­ãƒ¼ã§å¯¾å¿œå¯èƒ½: {matched_count}")
        print(f"   ğŸ†• æ–°è¦ã‚­ãƒ¼ãŒå¿…è¦: {new_needed_count}")
        
        return {
            'total': len(all_strings),
            'matched': matched_count,
            'new_needed': new_needed_count,
            'strings': all_strings
        }
    
    def save_analysis_result(self, result: Dict, output_file: str = "japanese_strings_analysis.json"):
        """åˆ†æçµæœã‚’JSONãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜"""
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(result, f, ensure_ascii=False, indent=2)
        print(f"\nâœ… åˆ†æçµæœã‚’ä¿å­˜: {output_file}")


if __name__ == "__main__":
    print("=" * 80)
    print("Phase 2: æ—¥æœ¬èªãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰æ¤œå‡ºãƒ»åˆ†é¡")
    print("=" * 80)
    
    extractor = JapaneseStringExtractor()
    result = extractor.extract_all_japanese_strings()
    extractor.save_analysis_result(result)
    
    print("\n" + "=" * 80)
    print("Phase 2 å®Œäº†ï¼")
    print("=" * 80)
